{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np \n",
    "import copy\n",
    "import gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MontezumaRevenge-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(18), Box(210, 160, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(input_tensor, output_size, scope, fsize, conv_depth, n_hidden_dense=0, activation=tf.tanh, output_activation=None):\n",
    "        with tf.variable_scope(scope):\n",
    "            x = input_tensor\n",
    "            # Convolutions\n",
    "            for _ in range(conv_depth):\n",
    "                x = tf.layers.conv2d(x, fsize, (3, 3), activation='relu')\n",
    "                x = tf.layers.conv2d(x, fsize, (3, 3), strides=(2, 2))\n",
    "            \n",
    "            # Dense Layers\n",
    "            x = tf.layers.flatten(x)\n",
    "            for _ in range(n_hidden_dense):\n",
    "                x = tf.layers.dense(x, fsize, activation=activation)\n",
    "            y = tf.layers.dense(x, output_size, activation=output_activation)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self, sess, graph_args, adv_args):\n",
    "        self.sess = sess\n",
    "        self.ob_dim = graph_args['ob_dim']\n",
    "        self.act_dim = graph_args['act_dim']\n",
    "        clip_range = graph_args['clip_range']\n",
    "        # conv operations params\n",
    "        conv_depth = graph_args['conv_depth']\n",
    "        filter_size = graph_args['filter_size']\n",
    "        \n",
    "        self.learning_rate = graph_args['learning_rate']\n",
    "        self.num_target_updates = graph_args['num_target_updates']\n",
    "        self.num_grad_steps_per_target_update = graph_args['num_grad_steps_per_target_update']\n",
    "        \n",
    "        self.gamma = adv_args['gamma']\n",
    "        \n",
    "        self.obs, self.act, self.adv, self.old_logprob = self.define_placeholders()\n",
    "        \n",
    "        # policy / actor evaluation\n",
    "        self.policy_distrib = Network(self.obs, self.act_dim, 'policy', filter_size, conv_depth)\n",
    "        self.greedy_action = tf.argmax(self.policy_distrib, axis=1)\n",
    "        self.logprob = self.get_logprob(self.policy_distrib, self.act)\n",
    "        \n",
    "        # importance sampling\n",
    "        ratio = tf.exp(self.logprob - self.old_logprob)\n",
    "        clipped_ratio = tf.clip_by_value(ratio, 1.0-clip_range, 1.0+clip_range)        \n",
    "        self.actor_loss = -1 * tf.reduce_mean(tf.minimum(ratio*self.adv, clipped_ratio*self.adv))\n",
    "        self.actor_update_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.actor_loss)\n",
    "        \n",
    "        # critic definition\n",
    "        self.v_pred = tf.squeeze(Network(self.obs, 1, 'critic', filter_size, conv_depth, n_hidden_dense=2))\n",
    "        self.v_target = tf.placeholder(shape=(None,), name='v_target', dtype=tf.float32)\n",
    "        self.critic_loss = tf.losses.mean_squared_error(self.v_target, self.v_pred)\n",
    "        # minimize with respect to correct variables HERE\n",
    "        self.critic_update_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.critic_loss)\n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        obs = tf.placeholder(shape=((None,) + (self.ob_dim)), name='obs', dtype=tf.float32)\n",
    "        act = tf.placeholder(shape=(None,), name='act', dtype=tf.int32)\n",
    "        adv = tf.placeholder(shape=(None,), name='adv', dtype=tf.float32)\n",
    "        logprob = tf.placeholder(shape=(None,), name='logprob', dtype=tf.float32)\n",
    "        return obs, act, adv, logprob\n",
    "    \n",
    "    def get_logprob(self, policy_distribution, actions):\n",
    "        action_enc = tf.one_hot(actions, depth=self.act_dim)\n",
    "        logprob = -1 * tf.nn.softmax_cross_entropy_with_logits_v2(logits=policy_distribution, labels=action_enc)\n",
    "        return logprob\n",
    "        \n",
    "    def get_best_action(self, observation):\n",
    "        act = sess.run(self.greedy_action, feed_dict={\n",
    "            self.obs: [observation]\n",
    "        })[0]\n",
    "        return act\n",
    "    \n",
    "    def estimate_adv(self, obs, rew, nxt_obs, dones):\n",
    "        # V(s) & V(s')\n",
    "        v_obs = self.sess.run(self.v_pred, feed_dict={self.obs: obs})\n",
    "        v_nxt_obs = self.sess.run(self.v_pred, feed_dict={self.obs: nxt_obs})\n",
    "        # y = r + gamma * V(s')\n",
    "        y_obs = rew + (1 - dones) * self.gamma * v_nxt_obs\n",
    "        # Adv(s) = y - V(s)\n",
    "        adv = y_obs - v_obs\n",
    "        # Normalize advantages\n",
    "        adv = (adv - np.mean(adv)) / (np.std(adv) + 1e-8)\n",
    "        return adv\n",
    "    \n",
    "    def train_actor(self, obs, act, logprob, adv):\n",
    "        self.sess.run(self.actor_update_op, feed_dict={\n",
    "            self.obs: obs,\n",
    "            self.act: act,\n",
    "            self.adv: adv,\n",
    "            self.old_logprob: logprob\n",
    "        })\n",
    "        \n",
    "    def train_critic(self, obs, nxt_obs, rew, dones):\n",
    "        for i in range(self.num_grad_steps_per_target_update * self.num_target_updates):\n",
    "            if i % self.num_grad_steps_per_target_update == 0:\n",
    "                v_pred = self.sess.run(self.v_pred, feed_dict={self.obs: nxt_obs})\n",
    "                y = rew + self.gamma * v_pred * (1 - dones)\n",
    "                \n",
    "            _, loss = self.sess.run([self.critic_update_op, self.critic_loss],\n",
    "                                    feed_dict={self.obs: obs, self.v_target: y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self):\n",
    "        self.obs = []\n",
    "        self.acts = []\n",
    "        self.rewards = []\n",
    "        self.nxt_obs = []\n",
    "        self.dones = []\n",
    "        self.logprobs = []\n",
    "    \n",
    "    def record(self, obs, act, rew, nxt_ob, done):\n",
    "        self.obs.append(obs)\n",
    "        self.acts.append(act)\n",
    "        self.rewards.append(rew)\n",
    "        self.nxt_obs.append(nxt_ob)\n",
    "        self.dones.append(done)\n",
    "        \n",
    "    def get_actions(self):\n",
    "        return np.asarray(self.obs), np.asarray(self.acts)\n",
    "    \n",
    "    def set_logprobs(self, logprobs):\n",
    "        self.logprobs += list(logprobs)\n",
    "        assert len(self.logprobs) == len(self.obs), 'logprobs MUST == self.obs'\n",
    "        \n",
    "    def merge(self, logprobs, obs, acts, rews, nxt_obs, dones):\n",
    "        self.obs += obs\n",
    "        self.acts += acts\n",
    "        self.rewards += rews\n",
    "        self.nxt_obs += nxt_obs\n",
    "        self.dones += dones\n",
    "        self.logprobs += list(logprobs)\n",
    "    \n",
    "    def export(self):\n",
    "        return self.obs, self.acts, self.rewards, self.nxt_obs, self.dones\n",
    "    \n",
    "    def get_samples(self, indices):\n",
    "        return (\n",
    "            np.asarray(self.obs)[indices],\n",
    "            np.asarray(self.acts)[indices],\n",
    "            np.asarray(self.rewards)[indices],\n",
    "            np.asarray(self.nxt_obs)[indices],\n",
    "            np.asarray(self.dones)[indices],\n",
    "            np.asarray(self.logprobs)[indices]\n",
    "        )\n",
    "    \n",
    "    def flush(self):\n",
    "        self.obs = []\n",
    "        self.acts = []\n",
    "        self.rewards = []\n",
    "        self.nxt_obs = []\n",
    "        self.dones = []\n",
    "        self.logprobs = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.obs)\n",
    "        \n",
    "class MasterBuffer(object):\n",
    "    def __init__(self):\n",
    "        self.master_replay = ReplayBuffer()\n",
    "        self.temp_replay = ReplayBuffer()\n",
    "    \n",
    "    def record(self, *args):\n",
    "        self.temp_replay.record(*args)\n",
    "        \n",
    "    def get_actions(self):\n",
    "        return self.temp_replay.get_actions()\n",
    "    \n",
    "    def get_obs(self):\n",
    "        return np.asarray(self.master_replay.obs)\n",
    "    \n",
    "    def set_logprobs(self, logprobs):\n",
    "        temp_data = self.temp_replay.export()\n",
    "        self.master_replay.merge(logprobs, *temp_data)\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        indices = np.random.randint(0, len(self.master_replay), batch_size)\n",
    "        return self.master_replay.get_samples(indices)\n",
    "    \n",
    "    ## Density Sampling Start ##\n",
    "    # credit to hw5\n",
    "    def get_density_batch(self, states, batch_size):\n",
    "        if len(self.master_replay) >= 2*len(states):\n",
    "            positives, negatives = self.sample_idxs_replay(states, batch_size)\n",
    "        else:\n",
    "            positives, negatives = self.sample_idxs(states, batch_size)\n",
    "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))], axis=0)\n",
    "        return positives, negatives, labels\n",
    "    \n",
    "    def sample_idxs(self, states, batch_size):\n",
    "        states = copy.deepcopy(states)\n",
    "        data_size = len(states)\n",
    "        pos_idxs = np.random.randint(data_size, size=batch_size)\n",
    "        continue_sampling = True\n",
    "        while continue_sampling:\n",
    "            neg_idxs = np.random.randint(data_size, size=batch_size)\n",
    "            if np.all(pos_idxs != neg_idxs):\n",
    "                continue_sampling = False\n",
    "        positives = np.concatenate([states[pos_idxs], states[pos_idxs]], axis=0)\n",
    "        negatives = np.concatenate([states[pos_idxs], states[neg_idxs]], axis=0)\n",
    "        return positives, negatives\n",
    "\n",
    "    def sample_idxs_replay(self, states, batch_size):\n",
    "        states = copy.deepcopy(states)\n",
    "        data_size = len(states)\n",
    "        pos_idxs = np.random.randint(data_size, size=batch_size)\n",
    "        neg_idxs = np.random.randint(data_size, len(self.master_replay), size=batch_size)\n",
    "        \n",
    "        buffer_states = self.get_obs()\n",
    "        positives = np.concatenate([states[pos_idxs], states[pos_idxs]], axis=0)\n",
    "        negatives = np.concatenate([states[pos_idxs], buffer_states[neg_idxs]], axis=0)\n",
    "        return positives, negatives\n",
    "    ## Density Sampling End ##\n",
    "    \n",
    "    def get_temp_reward_info(self):\n",
    "        rewards = np.asarray(self.temp_replay.rewards)\n",
    "        return np.sum(rewards), np.std(rewards)\n",
    "        \n",
    "    def flush_temp(self):\n",
    "        self.temp_replay.flush()\n",
    "    \n",
    "    def flush(self):\n",
    "        self.temp_replay.flush()\n",
    "        self.master_replay.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.tag = None\n",
    "        self.totalr = []\n",
    "        self.std_reward = []\n",
    "        \n",
    "        self.tags = []\n",
    "        self.results = []\n",
    "        \n",
    "    def set_tag(self, tag):\n",
    "        self.tag = tag\n",
    "        \n",
    "    def log(self, totalr, std):\n",
    "        self.totalr.append(totalr)\n",
    "        self.std_reward.append(std)\n",
    "        \n",
    "    def package_results(self):\n",
    "        # store\n",
    "        self.tags.append(self.tag)\n",
    "        self.results.append([self.totalr, self.std_reward])\n",
    "    \n",
    "    def flush(self):\n",
    "        self.totalr = []\n",
    "        self.std_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First test if policy works on simple task\n",
    "env = gym.make('CartPole-v0')\n",
    "tf.reset_default_graph()\n",
    "tf_config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\n",
    "# tf_config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    graph_args = {\n",
    "        'ob_dim': env.observation_space.shape,\n",
    "        'act_dim': env.action_space.n,\n",
    "        'clip_range': 0.2,\n",
    "        'learning_rate': 5e-3,\n",
    "        'num_target_updates': 10,\n",
    "        'num_grad_steps_per_target_update': 10\n",
    "    }    \n",
    "    \n",
    "    adv_args = {\n",
    "        'gamma': 0.9999999\n",
    "    }\n",
    "\n",
    "    # Setup\n",
    "    policy = Policy(sess, graph_args, adv_args)\n",
    "    replay_buffer = MasterBuffer()\n",
    "    logger = Logger()\n",
    "    agent = Agent(sess, env, policy, replay_buffer, logger)\n",
    "    \n",
    "    # init variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    n_iter = 100\n",
    "    num_samples = 100 \n",
    "    batch_sizes = [300]\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "        logger.set_tag('bs: '+str(bs))\n",
    "        replay_buffer.flush()\n",
    "        \n",
    "        for itr in range(n_iter):\n",
    "            agent.sample_env(num_samples)\n",
    "            agent.train(batch_size=bs)\n",
    "            agent.test(10)\n",
    "        \n",
    "        logger.package_results()\n",
    "        logger.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for results in logger.results:\n",
    "    totalr, stdr = results[0], results[1]\n",
    "    plt.plot(totalr)\n",
    "plt.title('AvgTotalReward vs Train Iteration')\n",
    "plt.xlabel('TrainIteration')\n",
    "plt.ylabel('AvgTotalReward')\n",
    "plt.legend(logger.tags, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityModel(object):\n",
    "    def __init__(self, sess, graph_args):\n",
    "        # un packing\n",
    "        self.sess = sess\n",
    "        self.ob_dim = graph_args['ob_dim']\n",
    "        self.learning_rate = graph_args['learning_rate']\n",
    "        self.z_size = graph_args['z_size']\n",
    "        self.kl_weight = graph_args['kl_weight']\n",
    "        # network operations params\n",
    "        self.hid_size = graph_args['hid_size']\n",
    "        self.n_hidden = graph_args['n_hidden']\n",
    "        \n",
    "        self.state1, self.state2 = self.define_placeholders()\n",
    "        # q(z_1 | s_1), q(z_2 | s_2), p(z), p(y | z)\n",
    "        self.encoder1, self.encoder2, self.prior, self.discriminator = self.forward_pass(self.state1, self.state2)\n",
    "        self.discrim_target = tf.placeholder(shape=[None, 1], name=\"discrim_target\", dtype=tf.float32)\n",
    "\n",
    "        self.log_likelihood = tf.squeeze(self.discriminator.log_prob(self.discrim_target), axis=1)\n",
    "        self.likelihood = tf.squeeze(self.discriminator.prob(self.discrim_target), axis=1)\n",
    "        \n",
    "        self.kl = self.encoder1.kl_divergence(self.prior) + self.encoder2.kl_divergence(self.prior)\n",
    "\n",
    "        assert len(self.log_likelihood.shape) == len(self.likelihood.shape) == len(self.kl.shape) == 1\n",
    "        \n",
    "        self.elbo = tf.reduce_mean(self.log_likelihood - self.kl_weight * self.kl)\n",
    "        self.update_op = tf.train.AdamOptimizer(self.learning_rate).minimize(-self.elbo)\n",
    "\n",
    "    def define_placeholders(self):\n",
    "        state1 = tf.placeholder(shape=((None,) + (self.ob_dim)), name=\"s1\", dtype=tf.float32)\n",
    "        state2 = tf.placeholder(shape=((None,) + (self.ob_dim)), name=\"s2\", dtype=tf.float32)\n",
    "        return state1, state2\n",
    "\n",
    "    #Network(input_tensor, output_size, scope, fsize, conv_depth, n_hidden_dense=0, activation=tf.tanh, output_activation=None):\n",
    "    def make_encoder(self, state, z_size, scope):\n",
    "        \"\"\" Encodes the given state to z_size => create guass. distribution for q(z | s)\n",
    "        \"\"\"\n",
    "        # conv operations\n",
    "        z_mean = Network(state, z_size, scope, self.hid_size, conv_depth=self.n_hidden)\n",
    "        z_logstd = tf.get_variable(\"logstd\", shape=(z_size,)) \n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=z_mean, scale_diag=tf.exp(z_logstd))\n",
    "\n",
    "    def make_prior(self, z_size):\n",
    "        \"\"\" Create Prior to map states too => p(z), we will use a normal guass distrib\n",
    "        \"\"\"\n",
    "        prior_mean = tf.zeros((z_size,))\n",
    "        prior_logstd = tf.zeros((z_size,))\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=prior_mean, scale_diag=tf.exp(prior_logstd))\n",
    "\n",
    "    def make_discriminator(self, z, output_size, scope, n_layers, hid_size):\n",
    "        \"\"\" Predict D(z = [z1, z2]) => p(y | z)\n",
    "        \"\"\"\n",
    "        logit = Network(z, output_size, scope, hid_size, conv_depth=0, n_hidden_dense=n_layers)\n",
    "        return tfp.distributions.Bernoulli(logit)\n",
    "\n",
    "    def forward_pass(self, state1, state2):\n",
    "        # Reuse\n",
    "        make_encoder1 = tf.make_template('encoder1', self.make_encoder)\n",
    "        make_encoder2 = tf.make_template('encoder2', self.make_encoder)\n",
    "        make_discriminator = tf.make_template('decoder', self.make_discriminator)\n",
    "\n",
    "        # Encoder\n",
    "        encoder1 = make_encoder1(state1, self.z_size, 'z1')\n",
    "        encoder2 = make_encoder2(state2, self.z_size, 'z2')\n",
    "\n",
    "        # Prior\n",
    "        prior = self.make_prior(self.z_size)\n",
    "\n",
    "        # Sampled Latent (some noise)\n",
    "        self.z1 = encoder1.sample()\n",
    "        z2 = encoder2.sample()\n",
    "        z = tf.concat([self.z1, z2], axis=1)\n",
    "\n",
    "        # Discriminator\n",
    "        discriminator = make_discriminator(z, 1, 'discriminator', self.n_hidden, self.hid_size)\n",
    "        return encoder1, encoder2, prior, discriminator\n",
    "\n",
    "    def update(self, state1, state2, target):\n",
    "        _, ll, kl, elbo = self.sess.run([self.update_op, self.log_likelihood, self.kl, self.elbo], feed_dict={\n",
    "            self.state1: state1,\n",
    "            self.state2: state2,\n",
    "            self.discrim_target: target\n",
    "        })\n",
    "        return ll, kl, elbo\n",
    "    \n",
    "    def get_encoding(self, state):\n",
    "        \"\"\"Assuming only encode a single state at a time\n",
    "        We will call this to use in our state dynamics fcn\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.z1, feed_dict={\n",
    "            self.state1: [state]\n",
    "        })[0]\n",
    "\n",
    "    def get_likelihood(self, state1, state2):\n",
    "        bs, _, _, _ = state1.shape\n",
    "        target = np.zeros((bs, 1))\n",
    "        for i, (s1, s2) in enumerate(zip(state1, state2)):\n",
    "            if s1.all() == s2.all(): target[i] = [1]\n",
    "\n",
    "        likelihood = self.sess.run(self.likelihood, feed_dict={\n",
    "            self.state1: state1,\n",
    "            self.state2: state2,\n",
    "            self.discrim_target: target\n",
    "        })\n",
    "        return likelihood\n",
    "\n",
    "    def get_prob(self, state):\n",
    "        likelihood = self.get_likelihood(state, state)\n",
    "        # avoid divide by 0 and log(0)\n",
    "        likelihood = np.clip(np.squeeze(likelihood), 1e-5, 1-1e-5)\n",
    "        prob = (1 - likelihood) / likelihood\n",
    "        return prob\n",
    "    \n",
    "    def modify_reward(self, state, rewards):\n",
    "        probs = self.get_prob(state)\n",
    "        bonus = -np.log(probs)\n",
    "        return rewards + 1e-3 * bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, sess, env, policy, density, replay_buffer, logger):\n",
    "        self.sess = sess\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.density = density\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.logger = logger\n",
    "        \n",
    "    def sample_env(self, num_samples):\n",
    "        obs = self.env.reset()\n",
    "        i = 0\n",
    "        while True:\n",
    "            act = self.choose_action(obs)\n",
    "            nxt_ob, rew, done, _ = env.step(act)\n",
    "            \n",
    "            replay_buffer.record(obs, act, rew, nxt_ob, done)\n",
    "            obs = nxt_ob if not done else env.reset()\n",
    "            i+=1\n",
    "            if i == num_samples - 1: break\n",
    "        \n",
    "        # get logprobs of taking actions w.r.t current policy\n",
    "        obs, actions = replay_buffer.get_actions()\n",
    "        logprobs = sess.run(policy.logprob, feed_dict={\n",
    "            policy.obs: obs,\n",
    "            policy.act: actions\n",
    "        })\n",
    "        replay_buffer.set_logprobs(logprobs)\n",
    "        replay_buffer.flush_temp()\n",
    "        \n",
    "    def choose_action(self, obs):\n",
    "        # Greedy action for now\n",
    "        return self.policy.get_best_action(obs)\n",
    "            \n",
    "    def train(self, batch_size):\n",
    "        obs, acts, rewards, nxt_obs, dones, logprobs = self.replay_buffer.get_batch(batch_size)\n",
    "        # inject exploration bonus\n",
    "        rewards = self.density.modify_reward(obs, rewards)\n",
    "\n",
    "        # train actor\n",
    "        adv = policy.estimate_adv(obs, rewards, nxt_obs, dones)\n",
    "        self.policy.train_actor(obs, acts, logprobs, adv)\n",
    "        \n",
    "        # train critic\n",
    "        self.policy.train_critic(obs, nxt_obs, rewards, dones)\n",
    "        \n",
    "        # train density model\n",
    "        s1, s2, target = self.replay_buffer.get_density_batch(obs, batch_size)\n",
    "        self.density.update(s1, s2, target)\n",
    "    \n",
    "    def test(self, num_tests, render=False, max_steps=1):\n",
    "        obs = self.env.reset()\n",
    "        i, step = 0, 0\n",
    "        while num_tests > i:\n",
    "            if render:\n",
    "                plt.imshow(env.render(mode='rgb_array'))\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "            act = self.policy.get_best_action(obs)\n",
    "            nxt_ob, rew, done, _ = env.step(act)\n",
    "            replay_buffer.record(obs, act, rew, nxt_ob, done)\n",
    "            obs = nxt_ob\n",
    "            if done or step > max_steps:\n",
    "                obs = env.reset()\n",
    "                i += 1\n",
    "                step = 0\n",
    "            step += 1\n",
    "            \n",
    "        totalr, stdr = replay_buffer.get_temp_reward_info()\n",
    "        logger.log(totalr / i, stdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train...\n",
      "iteration complete...\n"
     ]
    }
   ],
   "source": [
    "# test density fcn \n",
    "env = gym.make('MontezumaRevenge-v0')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf_config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\n",
    "# tf_config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    # defaults taken from homework\n",
    "    d_graph_args = {\n",
    "        'ob_dim': env.observation_space.shape,\n",
    "        'learning_rate': 5e-3,\n",
    "        'z_size': 32,\n",
    "        'kl_weight': 1e-2,\n",
    "        'conv_depth': 5,\n",
    "        'hid_size': 32,\n",
    "        'n_hidden': 4\n",
    "    }\n",
    "    p_graph_args = {\n",
    "        'ob_dim': env.observation_space.shape,\n",
    "        'act_dim': env.action_space.n,\n",
    "        'clip_range': 0.2,\n",
    "        'conv_depth': 5,\n",
    "        'filter_size': 32,\n",
    "        'learning_rate': 5e-3,\n",
    "        'num_target_updates': 10,\n",
    "        'num_grad_steps_per_target_update': 10\n",
    "    }\n",
    "    adv_args = {\n",
    "        'gamma': 0.9999999\n",
    "    }\n",
    "\n",
    "    # models\n",
    "    policy = Policy(sess, p_graph_args, adv_args)\n",
    "    density_model = DensityModel(sess, d_graph_args)\n",
    "    # utils\n",
    "    replay_buffer = MasterBuffer()\n",
    "    logger = Logger()\n",
    "    \n",
    "    # agent which will do all the work\n",
    "    agent = Agent(sess, env, policy, density_model, replay_buffer, logger)\n",
    "    \n",
    "    # init variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    n_iter = 1\n",
    "    num_samples = 100 \n",
    "    batch_sizes = [1] #50, 100, 300]\n",
    "\n",
    "    print('starting to train...')\n",
    "    for bs in batch_sizes:\n",
    "        logger.set_tag('bs: '+str(bs))\n",
    "        replay_buffer.flush()\n",
    "        \n",
    "        for itr in range(n_iter):\n",
    "            agent.sample_env(num_samples)\n",
    "            agent.train(batch_size=bs)\n",
    "            agent.test(1)\n",
    "        print('iteration complete...')\n",
    "        logger.package_results()\n",
    "        logger.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- transport code to GPU environment to test density function\n",
    "- split density training into seperate function <b>later</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
